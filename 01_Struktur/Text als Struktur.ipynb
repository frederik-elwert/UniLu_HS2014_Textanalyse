{
 "metadata": {
  "name": "",
  "signature": "sha256:e069dd4fd4952604c66f4af9f58559058e9d3f54646add0fe593d6790fa8dffb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Text als Struktur"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Vorbemerkung"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Textdaten k\u00f6nnen in unterschiedlichen Formen und Formaten vorliegen. In der computerbasierten Analyse ist mit Text zun\u00e4chst der \u00bbreine Text\u00ab gemeint, also Buchstabenfolgen ohne Formatierungen wie Fettdruck oder Textgliederungen wie \u00dcberschriften. Diese sind in Python einfache Zeichenketten bzw. Strings.\n",
      "\n",
      "Aus historischen Gr\u00fcnden \u2013 Amerika war fr\u00fch dominierend in der Computertechnologie, Amerikaner benutzen ein lateinisches Alphabet ohne Umlaute \u2013 ist die Unterst\u00fctzung f\u00fcr Sonderzeichen und nicht-westliche Sprachen vergleichsweise sp\u00e4t vereinheitlicht worden. Die Unterst\u00fctzung f\u00fcr nahezu alle Sprachen der Welt ist im sogenannten Unicode-Standard geregelt. In Python 2 m\u00fcssen daf\u00fcr Zeichenketten das Pr\u00e4fix *u* erhalten. In Python 3 ist die Unterst\u00fctzung daf\u00fcr standardm\u00e4\u00dfig aktiviert."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Ohne Pr\u00e4fix k\u00f6nnen merkw\u00fcrdige Effekte auftreten:\n",
      "len('T\u00fcr')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Mit Pr\u00e4fix funktioniert es:\n",
      "len(u'T\u00fcr')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Mehr als Text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Um Texten zus\u00e4tzliche Informationen wie etwa Textformatierungen oder Textstruktur hinzuzuf\u00fcgen, muss man den Text um Zusatzinformationen anreichern. Das ist die Aufgabe von Textformaten wie z.B. *doc*, *odt* oder *html*. [HTML](http://de.wikipedia.org/wiki/Hypertext_Markup_Language) ist dabei die \u00bbSprache des Internet\u00ab und vergleichsweise einfach aufgebaut."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "HTML(u'Meinst du <b>diese</b> T\u00fcr?')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "Meinst du <b>diese</b> T\u00fcr?"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "<IPython.core.display.HTML at 0x7f79e017be10>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Viele Daten liegen im Internet als HTML-Dateien vor. Diese sind f\u00fcr die Sozialwissenschaften h\u00e4ufig relevantes Analysematerial. Dabei m\u00fcssen in vielen F\u00e4llen zun\u00e4chst die relevanten Daten aus Internetseiten extrahiert werden. So beschreibt die Wikipedia das sogenannte [Screen Scraping](http://de.wikipedia.org/wiki/Screen_Scraping#Funktionsweise):\n",
      "\n",
      "> Screen Scraping besteht im Wesentlichen aus zwei Schritten:\n",
      ">\n",
      "> * Abrufen von Webseiten\n",
      "> * Extraktion der relevanten Daten\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "HTML-Dokumente k\u00f6nnen als Baumstruktur beschrieben werden:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from lxml import html\n",
      "doc = html.fromstring(u'''\n",
      "<html>\n",
      "  <head>\n",
      "    <title>Alles &#252;ber T&#252;ren</title>\n",
      "  </head>\n",
      "  <body>\n",
      "    <div id=\"content\">\n",
      "      <h1>Welche T&#252;r passt zu mir?</h1>\n",
      "      <p class=\"teaser\">Das k&#246;nnen Sie auf <b>dieser Seite</b> herausfinden.</p>\n",
      "      <p>Machen Sie unseren <a href=\"test.html\">Test!</a></p>\n",
      "    </div>\n",
      "    <div id=\"nav\">\n",
      "      <ul>\n",
      "        <li><a href=\"fenster.html\">Fenster</a></li>\n",
      "        <li><a href=\"luken.html\">Luken</a></li>\n",
      "      </ul\n",
      "    </div>\n",
      "  </body>\n",
      "</html>\n",
      "''')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for element in doc.iter():\n",
      "    indent = len(list(element.iterancestors()))\n",
      "    print '{space}- {tag}'.format(space=u'  ' * indent,\n",
      "                                  tag=element.tag)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "- html\n",
        "  - head\n",
        "    - title\n",
        "  - body\n",
        "    - div\n",
        "      - h1\n",
        "      - p\n",
        "        - b\n",
        "      - p\n",
        "        - a\n",
        "    - div\n",
        "      - ul\n",
        "        - li\n",
        "          - a\n",
        "        - li\n",
        "          - a\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aus dieser Baumstruktur lassen sich gezielt bestimmte Informationen extrahieren. Dazu gibt es zwei Methoden: XPath und CSS."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "XPath"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Die Ordnerstruktur einer Festplatte oder die Navigation einer Website l\u00e4sst sich auch als Baum beschreiben, wie etwa im [Inhaltsverzeichnis](https://www.unilu.ch/inhaltsverzeichnis/) der Uni Luzern. Ein bestimmtes Element in diesem Baum l\u00e4sst sich \u00fcber einen Pfad beschreiben:\n",
      "\n",
      "![Website des Soziologischen Seminars](Bilder/UniLU.png)\n",
      "\n",
      "\u00c4hnlich funktioniert dies auch mit dem HTML-Dokument. Dabei k\u00f6nnen aber an einer Adresse mehrere Elemente sitzen, eine Adresse gibt daher immer eine Liste von passenden Elementen zur\u00fcck:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc.xpath('/html/body/p')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc.xpath('/html/body/h1/text()')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Aber:\n",
      "doc.xpath('/html/body/p/text()')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Daher besser:\n",
      "[p.text_content() for p in doc.xpath('/html/body/p')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Kurzformen\n",
      "doc.xpath('//p')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[<Element p at 0x7f79e00651b0>, <Element p at 0x7f79e0065208>]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reale Webseiten enthalten oft eine Menge zus\u00e4tzlicher Elemente, die f\u00fcr die Textanalyse st\u00f6rend sind, wie z.B. Navigation, Anzeigen, Kopfzeilen und dekorative Elemente. Um gezielt die relevanten Passagen zu finden, muss man die Pfade oft mit zus\u00e4tzlichen Filterbedingungen einschr\u00e4nken. Typische Kriterien k\u00f6nnen hier die HTML-Attribute *id* und *class* sein, die oft zur Strukturierung von Webseiten eingesetzt werden. Hier ist XPath sehr vielseitig:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc.xpath('//p[@class=\"teaser\"]')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[<Element p at 0x7f79e00651b0>]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc.xpath('//div[@id=\"nav\"]//a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[<Element a at 0x7f79e0065310>, <Element a at 0x7f79e00d5e68>]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "CSS"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Die Syntax f\u00fcr diese Bedingungen ist zwar sehr flexibel, aber auch recht kompliziert. In den meisten F\u00e4llen bietet sich eine einfachere Variante an, die auf die Besonderheiten von HTML zugeschnitten ist: CSS-Selektoren. [CSS](http://de.wikipedia.org/wiki/Cascading_Style_Sheets) ist eigentlich eine Sprache f\u00fcr die Formatierung von Webseiten. Sie enth\u00e4lt aber eine M\u00f6glichkeit, Elemente in HTML-Dokumenten auszuw\u00e4hlen, die sich auch in anderen Kontexten einsetzen l\u00e4sst. Ihre Hauptelemente sind dabei Tag-Namen, IDs und Klassen."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "doc.cssselect('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "[<Element a at 0x7f79e00848e8>,\n",
        " <Element a at 0x7f79e0065310>,\n",
        " <Element a at 0x7f79e00d5e68>]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IDs (z.B. <div id=\"nav\">)\n",
      "doc.cssselect('#nav a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "[<Element a at 0x7f79e0065310>, <Element a at 0x7f79e00d5e68>]"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Klassen (z.B. <p class=\"teaser\">)\n",
      "doc.cssselect('p.teaser')  # oder nur '.teaser'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[<Element p at 0x7f79e00651b0>]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Eine ausf\u00fchrliche Dokumentation der unterschiedlichen Selektoren findet sich [hier](http://wiki.selfhtml.org/wiki/CSS/Selektoren). Ein Hilfsmittel, um CSS-Selektoren zu finden, ist [Selector Gadget](http://selectorgadget.com/)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Ein echtes Beispiel"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Nehmen wir als Beispiel eine [Rede der deutschen Bundeskanzlerin](http://www.bundesregierung.de/Content/DE/Rede/2014/09/2014-09-17-merkel-jugend-forscht.html) von der Website der deutschen Bundesregierung. Wir wollen den Titel, das Datum, den Teaser und den Text dieser Seite f\u00fcr weitere Analysen extrahieren."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rede = html.parse('http://www.bundesregierung.de/Content/DE/Rede/2014/09/2014-09-17-merkel-jugend-forscht.html')\n",
      "root = rede.getroot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Titel\n",
      "root.cssselect('.text h1')[0].text_content()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "u'Rede von Bundeskanzlerin Merkel zum Empfang der Preistr\\xe4gerinnen und Preistr\\xe4ger des 49. Bundeswettbewerbs \\u201eJugend forscht\\u201c am 17. September 2014'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Teaser\n",
      "root.cssselect('.text .abstract')[0].text_content()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "'im Bundeskanzleramt\\n'"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Das Datum ist etwas komplizierter: Diese Kopfangaben auf der Seite bestehen aus Definitionslisten ([dl](http://wiki.selfhtml.org/wiki/HTML/Textstrukturierung/dl)) mit dem folgenden Aufbau:\n",
      "\n",
      "```html\n",
      "<dl>\n",
      "    <dt>Datum:</dt><dd>17. September 2014</dd>\n",
      "    <dt>Ort:</dt><dd>Berlin</dd>\n",
      "</dl>\n",
      "```\n",
      "\n",
      "In diesem Fall ist nur das Datum in dieser Form angegeben, aber bei anderen Reden ist dies unterschiedlich. In Python l\u00e4sst sich das Datum so herausfiltern:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Datum\n",
      "labels = root.cssselect('.text dl dt')\n",
      "contents = root.cssselect('.text dl dd')\n",
      "date = None\n",
      "for label, content in zip(labels, contents):\n",
      "    if 'Datum' in label.text_content():\n",
      "        date = content.text_content()\n",
      "        break\n",
      "date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "'17. September 2014'"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Text\n",
      "pars = root.cssselect('.text .abstract ~ p')  # Alle p-Elemente hinter .abstract\n",
      "text = '\\n\\n'.join([par.text_content() for par in pars])\n",
      "text[0:200]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "u'Lieber Herr Baszio,\\nliebe Frau Wanka,\\nmeine Damen und Herren,\\naber vor allem: liebe Preistr\\xe4gerinnen und Preistr\\xe4ger von \\u201eJugend forscht\\u201c,\\n\\nich habe Ihnen einen der spannenden Termine im Kalenderjahr '"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Auf diese Weise lassen sich nun die relevanten Inhalte aller Seiten herausfiltern. In der Praxis w\u00fcrde man auch hier nicht Seite f\u00fcr Seite einzeln aufrufen, sondern auf \u00e4hnliche Weise auf einer \u00dcbersichtsseite alle Links zu den einzelnen Texten herausfiltern und diese automatisch abarbeiten. F\u00fcr gr\u00f6\u00dfere Projekte bietet sich [Scrapy](http://doc.scrapy.org/en/latest/intro/tutorial.html) an, das die Ergebnisse direkt in einer Tabelle speichern kann. Im Ordner *politikdokumente* findet sich ein Beispiel f\u00fcr ein solches Scrapy-Projekt."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}