{
 "metadata": {
  "name": "",
  "signature": "sha256:922ff0121cfaada6478bfe3b92244269712514687fe0bb75874ebe0b134e61ef"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Anwendung 1: Keyword Extraction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Eine m\u00f6gliche Anwendung von Textanalysen auf der Grundlage eines Vector-Space-Modells ist die Identifikation von Schl\u00fcsselw\u00f6rtern f\u00fcr Texte, die \u00bbKeyword Extraction\u00ab. Ein Schl\u00fcsselwort kann verstanden werden als ein Wort, dass einen inhaltlichen Aspekt eines Textes beschreibt. Eine begrenzte Anzahl von Schl\u00fcsselw\u00f6rtern sollte also bereits einen guten Eindruck vom Inhalt eines Textes vermitteln. Schlagwortsysteme, etwa in Bibliothekskatalogen oder Literaturdatenbanken, bauen auf dieser Idee auf. Sie erfordern aber eine sorgf\u00e4ltige manuelle Verschlagwortung. Daher ist die Frage interessant, ob sich Schl\u00fcsselw\u00f6rter f\u00fcr Texte auch automatisch aus dem Textinhalt erschlie\u00dfen lassen.\n",
      "\n",
      "Ein erster Kandidat f\u00fcr die Identifikation w\u00e4re die reine Worth\u00e4ufigkeit: F\u00fcr einen Text relevante W\u00f6rter sollten in ihm h\u00e4ufig vorkommen. Die H\u00e4ufigkeitsausz\u00e4hlungen aus den vorangegangenen Einheiten zeigen aber, dass eine reine H\u00e4ufigkeitsliste nicht sehr hilfreich ist: Zun\u00e4chst erscheinen Funktionw\u00f6rter wie etwa Artikel ganz oben in der Liste. Aber auch wenn man nach Wortarten filtert, bleiben oft relativ unspezifische W\u00f6rter dominant.\n",
      "\n",
      "Der Keyword Extraction liegt daher die Annahme zugrunde, dass einige W\u00f6rter insgesamt h\u00e4ufig vorkommen, ohne dass sie inhaltlich aussagekr\u00e4ftig w\u00e4ren. Ihr h\u00e4ufiges Vorkommen ist daher eher charakteristisch f\u00fcr eine (Fach-)Sprache als f\u00fcr einzelne Texte. Die Verteilung dieser W\u00f6rter sollte entsprechend \u00fcber die Texte relativ gleich bleiben. Ein Schl\u00fcsselwort dagegen sollte im entsprechenden Text deutlich h\u00e4ufiger vorkommen als im Gesamtkorpus. Statistisch l\u00e4sst sich ein Schl\u00fcsselwort also definieren als ein Wort, das in einem einzelnen Text signifikant h\u00e4ufiger vorkommt als seine H\u00e4ufigkeit im Gesamtcorpus erwarten lassen w\u00fcrde.\n",
      "\n",
      "Eine Form einer entsprechenden Identifikation von Schl\u00fcsselw\u00f6rtern ist [Tf-Idf](http://de.wikipedia.org/wiki/Tf-idf-Ma%C3%9F). Das K\u00fcrzel steht dabei f\u00fcr \u00bbTermfrequenz \u2013 Inverse Dokumentfrequenz\u00ab.\n",
      "\n",
      "Dieses Verfahren ist in gensim implementiert. Daf\u00fcr wird die in der vorangegangenen Einheit vorgestellte Corpus-Klasse verwendet."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.corpora.textcorpus import TextCorpus\n",
      "from textblob_de import TextBlobDE as TextBlob\n",
      "import pandas as pd\n",
      "\n",
      "class CSVCorpus(TextCorpus):\n",
      "    \"\"\"Read corpus from a csv file.\"\"\"\n",
      "\n",
      "    def get_texts(self):\n",
      "        with self.getstream() as csvfile:  # \u00d6ffnet die CSV-Datei\n",
      "            table = pd.read_csv(csvfile, parse_dates=['date'], encoding='utf-8')  # Liest die CSV-Datei\n",
      "            for text in table['text']:  # Verarbeite die einzelnen Texte aus der Spalte 'text'\n",
      "                blob = TextBlob(text)\n",
      "                yield blob.words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Das Vorgehen in gensim ist dabei nicht ganz selbsterkl\u00e4ren, daher hier eine kurze Erl\u00e4uterung: Der Befehl `TfidfModel(corpus)` erzeugt zun\u00e4chst ein Modell, das die allgemeine H\u00e4ufigkeitsverteilung von W\u00f6rtern im Corpus enth\u00e4lt. Mit diesem Modell k\u00f6nnen nun einzelne Dokumente, aber auch nur einzelne W\u00f6rter aus einem Dokument, verglichen werden. Dies ist etwa dann sinnvoll, wenn eine Berechnung f\u00fcr das gesamte Corpus zu aufw\u00e4ndig w\u00e4re, oder wenn neue Texte hinzukommen, die mit einem bestehenden Corpus verglichen werden sollen.\n",
      "\n",
      "Um dagegen f\u00fcr das gesamte Corpus die Tf-Idf-Werte zu berechnen, wird dem Modell im zweiten Schritt einfach wiederum das gesamte Corpus \u00fcbergeben: `tf_idf[corpus]`. In diesem Schritt findet dann die eigentliche Berechnung f\u00fcr die einzelnen Dokument statt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models import TfidfModel\n",
      "\n",
      "corpus = CSVCorpus(\"../Daten/reden.csv\")\n",
      "tf_idf = TfidfModel(corpus)\n",
      "corpus_idf = tf_idf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dies gibt f\u00fcr jedes Wort in jedem Dokument einen Wert aus. Das Format ist dabei das gleiche wie f\u00fcr Corpora, nur dass anstelle der reinen Worth\u00e4ufigkeiten der tfidf-Wert ausgegeben wird. Ein Dokument ist also eine Liste aus `(wortindex, wert)`-Paaren.\n",
      "\n",
      "Um nun f\u00fcr einzelne Dokumente die Schl\u00fcsselw\u00f6rter zu bestimmen, ist es sinnvoll, die W\u00f6rter im Dokument nach ihrem tfidf-Wert zu sortieren. Zugleich interessieren nicht die numerischen Wort-Indices, sondern die eigentlichen W\u00f6rter. Daher wird hier eine Funktion `keywords` definiert, die das Dokument zun\u00e4chst nach tfidf-Wert (dem zweiten Eintrag im Wort-Wert-Paar: `x[1]`) sortiert und dann ein Paar aus W\u00f6rterbucheintrag `corpus.dictionary[term]` und tfidf-Wert ausgibt."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def keywords(corpus, doc_tf_idf):\n",
      "    return [(corpus.dictionary[term], value)\n",
      "            for term, value\n",
      "            in sorted(doc_tf_idf, key=lambda x: x[1], reverse=True)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "F\u00fcr die ersten zehn Dokumente k\u00f6nnen nun etwa jeweils f\u00fcnf Schl\u00fcsselw\u00f6rter ausgegeben werden:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, doc in enumerate(corpus_idf):\n",
      "    if i == 9:\n",
      "        break\n",
      "    print\n",
      "    for keyword, value in keywords(corpus, doc)[0:5]:\n",
      "        print u'  {} ({})'.format(keyword, value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Safranski (0.472750464052)\n",
        "  R\u00fcdiger (0.337367236021)\n",
        "  Wahrheiten (0.138215543768)\n",
        "  Utopien (0.126066790414)\n",
        "  Romantik (0.104493794377)\n",
        "\n",
        "  \u201eElektromobilit\u00e4t\u201c (0.372779168826)\n",
        "  Stecker (0.372435485485)\n",
        "  Elektromobilit\u00e4t (0.173383544659)\n",
        "  Pr\u00e4sentation (0.171540045793)\n",
        "  China (0.162105143183)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Nachhaltigkeit (0.294015094791)\n",
        "  China (0.291787735475)\n",
        "  Universit\u00e4t (0.109320088669)\n",
        "  Innovationspartnerschaft (0.1065077783)\n",
        "  Chinas (0.102461803818)\n",
        "\n",
        "  Tempelhof (0.556694789109)\n",
        "  Flughafen (0.292116704843)\n",
        "  AlliiertenMuseum (0.209741456143)\n",
        "  Berlin-Tempelhof (0.151825851575)\n",
        "  Miniaturbild (0.151825851575)\n",
        "\n",
        "  \u201eSonne\u201c (0.446115651832)\n",
        "  Schiff (0.272536385343)\n",
        "  Neptun (0.227323234857)\n",
        "  Werft (0.213883738352)\n",
        "  Meeresforschung (0.188422877129)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Klimaschutz (0.192756524708)\n",
        "  Hendricks (0.152513059156)\n",
        "  Umweltminister (0.14994348321)\n",
        "  Energien (0.13244948829)\n",
        "  2030 (0.125330990937)\n",
        "\n",
        "  Bev\u00f6lkerungsschutz (0.211489490766)\n",
        "  Bev\u00f6lkerungsschutzes (0.211489490766)\n",
        "  Haupt (0.185891928075)\n",
        "  Verzicht (0.165225609843)\n",
        "  freiwilligen (0.148534035723)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  Wirtschaftswissenschaften (0.164377237199)\n",
        "  Wissenschaft (0.158895097718)\n",
        "  Lindau (0.138204437541)\n",
        "  Theorien (0.13284385955)\n",
        "  Politikberatung (0.108361418257)\n",
        "\n",
        "  Vertriebenen (0.648749225458)\n",
        "  Vertreibung (0.296323531462)\n",
        "  Flucht (0.258747401451)\n",
        "  Heimat (0.115601389578)\n",
        "  Schicksal (0.114708666597)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hier ist auff\u00e4llig, dass fast nur Substantive ausgegeben werden, obwohl das Corpus selbst die W\u00f6rter \u00fcberhaupt nicht gefiltert hat. Dies legt den Schluss nahe, dass andere Wortarten deutlich gleicher \u00fcber das Corpus verteilt sind.\n",
      "\n",
      "Um die Plausibilit\u00e4t dieser Listen zu \u00fcberpr\u00fcfen, k\u00f6nnen zus\u00e4tzlich die Titel der Dokumente ausgegeben werden:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.read_csv(\"../Daten/reden.csv\", parse_dates=['date'], encoding='utf-8')\n",
      "\n",
      "for i, doc in enumerate(corpus_idf):\n",
      "    if i == 9:\n",
      "        break\n",
      "    print\n",
      "    print data['title'][i]\n",
      "    for keyword, value in keywords(corpus, doc)[0:5]:\n",
      "        print u'  {} ({})'.format(keyword, value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Laudatio auf R\u00fcdiger Safranski\n",
        "  Safranski (0.472750464052)\n",
        "  R\u00fcdiger (0.337367236021)\n",
        "  Wahrheiten (0.138215543768)\n",
        "  Utopien (0.126066790414)\n",
        "  Romantik (0.104493794377)\n",
        "\n",
        "Rede von Bundeskanzlerin Merkel anl\u00e4sslich der Pr\u00e4sentation des deutsch-chinesischen Kooperationsprojekts zur Ladeinfrastruktur f\u00fcr Elektrofahrzeuge am 8. Juli 2014\n",
        "  \u201eElektromobilit\u00e4t\u201c (0.372779168826)\n",
        "  Stecker (0.372435485485)\n",
        "  Elektromobilit\u00e4t (0.173383544659)\n",
        "  Pr\u00e4sentation (0.171540045793)\n",
        "  China (0.162105143183)\n",
        "\n",
        "Rede von Bundeskanzlerin Merkel anl\u00e4sslich des Besuchs der Tsinghua - Universit\u00e4t am 8. Juli 2014\n",
        "  Nachhaltigkeit (0.294015094791)\n",
        "  China (0.291787735475)\n",
        "  Universit\u00e4t (0.109320088669)\n",
        "  Innovationspartnerschaft (0.1065077783)\n",
        "  Chinas (0.102461803818)\n",
        "\n",
        "Kulturstaatsministerin Monika Gr\u00fctters zur Er\u00f6ffnung der Sonderausstellung\r\n",
        "\"Flughafen Berlin-Tempelhof - Die amerikanische Geschichte\"\n",
        "  Tempelhof (0.556694789109)\n",
        "  Flughafen (0.292116704843)\n",
        "  AlliiertenMuseum (0.209741456143)\n",
        "  Berlin-Tempelhof (0.151825851575)\n",
        "  Miniaturbild (0.151825851575)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rede von Bundeskanzlerin Merkel anl\u00e4sslich der Taufe des Tiefseeforschungsschiffs \u201eSonne\u201c am 11. Juli 2014 \n",
        "  \u201eSonne\u201c (0.446115651832)\n",
        "  Schiff (0.272536385343)\n",
        "  Neptun (0.227323234857)\n",
        "  Werft (0.213883738352)\n",
        "  Meeresforschung (0.188422877129)\n",
        "\n",
        "Rede von Bundeskanzlerin Merkel anl\u00e4sslich des 5. Petersberger Klimadialogs am 14. Juli 2014\n",
        "  Klimaschutz (0.192756524708)\n",
        "  Hendricks (0.152513059156)\n",
        "  Umweltminister (0.14994348321)\n",
        "  Energien (0.13244948829)\n",
        "  2030 (0.125330990937)\n",
        "\n",
        "Rede von Bundeskanzlerin Merkel zum Treffen mit BBK, THW und den Hilfsorganisationen im Bereich des Bev\u00f6lkerungsschutzes am 19. August 2014 in Bonn\n",
        "  Bev\u00f6lkerungsschutz (0.211489490766)\n",
        "  Bev\u00f6lkerungsschutzes (0.211489490766)\n",
        "  Haupt (0.185891928075)\n",
        "  Verzicht (0.165225609843)\n",
        "  freiwilligen (0.148534035723)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Rede von Bundeskanzlerin Merkel zum 5. Treffen der Nobelpreistr\u00e4ger\n",
        "  Wirtschaftswissenschaften (0.164377237199)\n",
        "  Wissenschaft (0.158895097718)\n",
        "  Lindau (0.138204437541)\n",
        "  Theorien (0.13284385955)\n",
        "  Politikberatung (0.108361418257)\n",
        "\n",
        "Rede von Bundeskanzlerin Merkel zum Tag der Heimat am 30. August 2014\n",
        "  Vertriebenen (0.648749225458)\n",
        "  Vertreibung (0.296323531462)\n",
        "  Flucht (0.258747401451)\n",
        "  Heimat (0.115601389578)\n",
        "  Schicksal (0.114708666597)\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}